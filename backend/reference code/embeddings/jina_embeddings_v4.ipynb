{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsR2fy851u43"
      },
      "outputs": [],
      "source": [
        "# !pip install -U transformers peft torch ipywidgets jupyter Torchvision\n",
        "# !pip install transformers>=4.52.0 torch>=2.6.0 peft>=0.15.2 torchvision pillow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnerPObQ1u45"
      },
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/jinaai/jina-embeddings-v4\n",
        "\n",
        "‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/jinaai/jina-embeddings-v4)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!hf auth whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"MPS available:\", torch.backends.mps.is_available())\n",
        "print(\"Device:\", \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v4\", trust_remote_code=True, dtype=torch.float16)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 1. Retrieval Task\n",
        "# ========================\n",
        "# Configure truncate_dim, max_length (for texts), max_pixels (for images), vector_type, batch_size in the encode function if needed\n",
        "\n",
        "# Encode query\n",
        "query_embeddings = model.encode_text(\n",
        "    texts=[\"Overview of climate change impacts on coastal cities\"],\n",
        "    task=\"retrieval\",\n",
        "    prompt_name=\"query\",\n",
        ")\n",
        "\n",
        "# Encode passage (text)\n",
        "passage_embeddings = model.encode_text(\n",
        "    texts=[\n",
        "        \"Climate change has led to rising sea levels, increased frequency of extreme weather events...\"\n",
        "    ],\n",
        "    task=\"retrieval\",\n",
        "    prompt_name=\"passage\",\n",
        ")\n",
        "\n",
        "# Encode image/document\n",
        "image_embeddings = model.encode_image(\n",
        "    images=[\"https://i.ibb.co/nQNGqL0/beach1.jpg\"],\n",
        "    task=\"retrieval\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 2. Text Matching Task\n",
        "# ========================\n",
        "texts = [\n",
        "    \"ÿ∫ÿ±Ÿàÿ® ÿ¨ŸÖŸäŸÑ ÿπŸÑŸâ ÿßŸÑÿ¥ÿßÿ∑ÿ¶\",  # Arabic\n",
        "    \"Êµ∑Êª©‰∏äÁæé‰∏ΩÁöÑÊó•ËêΩ\",  # Chinese\n",
        "    \"Un beau coucher de soleil sur la plage\",  # French\n",
        "    \"Ein wundersch√∂ner Sonnenuntergang am Strand\",  # German\n",
        "    \"ŒàŒΩŒ± œåŒºŒøœÅœÜŒø Œ∑ŒªŒπŒøŒ≤Œ±œÉŒØŒªŒµŒºŒ± œÄŒ¨ŒΩœâ Œ±œÄœå œÑŒ∑ŒΩ œÄŒ±œÅŒ±ŒªŒØŒ±\",  # Greek\n",
        "    \"‡§∏‡§Æ‡•Å‡§¶‡•ç‡§∞ ‡§§‡§ü ‡§™‡§∞ ‡§è‡§ï ‡§ñ‡•Ç‡§¨‡§∏‡•Ç‡§∞‡§§ ‡§∏‡•Ç‡§∞‡•ç‡§Ø‡§æ‡§∏‡•ç‡§§\",  # Hindi\n",
        "    \"Un bellissimo tramonto sulla spiaggia\",  # Italian\n",
        "    \"ÊµúËæ∫„Å´Ê≤à„ÇÄÁæé„Åó„ÅÑÂ§ïÊó•\",  # Japanese\n",
        "    \"Ìï¥Î≥Ä ÏúÑÎ°ú ÏïÑÎ¶ÑÎã§Ïö¥ ÏùºÎ™∞\",  # Korean\n",
        "]\n",
        "\n",
        "text_embeddings = model.encode_text(texts=texts, task=\"text-matching\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 3. Code Understanding Task\n",
        "# ========================\n",
        "\n",
        "# Encode query\n",
        "query_embedding = model.encode_text(\n",
        "    texts=[\"Find a function that prints a greeting message to the console\"],\n",
        "    task=\"code\",\n",
        "    prompt_name=\"query\",\n",
        ")\n",
        "\n",
        "# Encode code\n",
        "code_embeddings = model.encode_text(\n",
        "    texts=[\"def hello_world():\\n    print('Hello, World!')\"],\n",
        "    task=\"code\",\n",
        "    prompt_name=\"passage\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 4. Use multivectors\n",
        "# ========================\n",
        "\n",
        "multivector_embeddings = model.encode_text(\n",
        "    texts=texts,\n",
        "    task=\"retrieval\",\n",
        "    prompt_name=\"query\",\n",
        "    return_multivector=True,\n",
        ")\n",
        "\n",
        "images = [\"https://i.ibb.co/nQNGqL0/beach1.jpg\", \"https://i.ibb.co/r5w8hG8/beach2.jpg\"]\n",
        "multivector_image_embeddings = model.encode_image(\n",
        "    images=images,\n",
        "    task=\"retrieval\",\n",
        "    return_multivector=True,\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "kernelspec": {
      "display_name": "rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
